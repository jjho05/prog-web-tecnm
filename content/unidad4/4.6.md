# 4.6 Acceso a Datos (La Capa de Persistencia)

Una aplicación que no guarda datos no sirve de mucho.
Aquí decides dónde vivirá tu información.

---

## SQL vs NoSQL (La Guerra Santa)

Antes de escribir código, debes elegir tu base de datos.

### SQL (Relacional)
*   Estructura rígida (Tablas y Columnas).
*   Ideal para datos estructurados y relaciones complejas (Usuarios, Ventas, Inventario).
*   Garantiza consistencia (ACID). Ejs: MySQL, PostgreSQL.

### NoSQL (Flexible)
*   Sin esquema fijo (Schema-less).
*   Ideal para datos variables, logs, o prototipos rápidos.
*   Ejs: MongoDB (Documentos), Redis (Cache).

---

## Pool de Conexiones (Performance Crítico)

### El Pool de Conexiones
No abras y cierres la conexión en cada petición. Es lento.
Usa un **Pool**: Mantiene conexiones vivas y las "presta" a las peticiones cuando llegan. Si se acaban, las peticiones esperan (Queue).

---

## ORM vs Query Builder vs SQL Puro

¿Qué nivel de abstracción quieres?

### Opciones de Acceso
1.  **SQL Puro (`pg`):** Máximo control y rendimiento, pero tedioso y riesgo de SQL Injection.
2.  **Query Builder (`Knex`):** Escribes JS que genera SQL. Más cómodo.
3.  **ORM (`Prisma`, `TypeORM`):** Tratas tu DB como objetos de código.
    *   **Prisma:** Es el estándar moderno. Te da autocompletado de TypeScript y migraciones automáticas. **Recomendado.**

---

---

## Transacciones ACID (Todo o Nada)

Vas al cajero. El banco te resta $500, pero la máquina se traba y no te da el dinero.
¿Perdiste $500? No, gracias a las transacciones.

### Anatomía de una Transacción
1.  **BEGIN:** Inicia el modo seguro.
2.  **Operación A:** Restar saldo.
3.  **Operación B:** Entregar billetes (Falló!).
4.  **ROLLBACK:** Deshaz TODO lo que pasó desde BEGIN.
5.  **COMMIT:** Si todo salió bien, guarda los cambios permanentemente.

### En Prisma
```javascript
try {
    const result = await prisma.$transaction([
        prisma.user.update({ ... }),
        prisma.auditLog.create({ ... })
    ]);
} catch (error) {
    // Si uno falla, AMBOS se cancelan automáticamente.
}
```

---

## Migraciones (Git para tu Base de Datos)

Nunca crees tablas manualmente en producción (`CREATE TABLE`).
Usa migraciones. Son archivos que describen los cambios.

### Migraciones (Control de Versiones para DB)
Nunca crees tablas manualmente. Usa migraciones.
Son archivos que guardan el historial de cambios:
1.  `001_create_users.sql`
2.  `002_add_age_column.sql`
Así, cualquier dev del equipo puede correr `migrate` y tener la DB lista.

---

## Seeding (Datos Semilla)

Tu base de datos nueva está vacía. ¿Cómo pruebas el Frontend?
Creas un script `seed.js` que inserta datos falsos.

```javascript
/* seed.js */
const { PrismaClient } = require('@prisma/client');
const prisma = new PrismaClient();

async function main() {
    await prisma.user.createMany({
        data: [
            { email: 'admin@test.com', role: 'ADMIN' },
            { email: 'user@test.com', role: 'USER' },
        ]
    });
}

main();
```
*   **Pro Tip:** Usa la librería `faker` (ahora `@faker-js/faker`) para generar miles de nombres realistas.

---

---

## Índices (Acelerando Consultas)

Buscar en una tabla de 1 millón de usuarios sin índice es escanear 1 millón de filas (`O(N)`).
Con índice (B-Tree), es `O(log N)` (~20 saltos).

### Cuándo Indexar
*   Columnas donde usas `WHERE`, `ORDER BY` o `JOIN`.
*   Ej: `email`, `last_login`, `foreign_keys`.
*   **No indexes todo:** Indexar ralentiza los `INSERT` y `UPDATE`.

---

## El Problema N+1 (El Asesino de Performance)

Cargas 10 usuarios. Luego, por cada uno, haces una consulta para ver sus posts.
Total: 1 consulta de usuarios + 10 consultas de posts = 11 consultas.
Si son 1000 usuarios -> 1001 consultas. La DB muere.

### El Problema N+1
Si cargas 10 usuarios y luego haces una consulta *por cada uno* para ver sus posts, haces 11 consultas. Si son 1000 usuarios, la DB explota.
*   **Solución (Eager Loading):** Pide los usuarios CON sus posts en una sola consulta (`include` en Prisma, `JOIN` en SQL).

---

## Soft Deletes (Borrado Suave)

En sistemas serios, `DELETE FROM users` está prohibido.
Si un usuario "borra" su cuenta, solo marcas `deletedAt = NOW()`.

### Implementación en Prisma Middleware
```javascript
prisma.$use(async (params, next) => {
    // Interceptar Delete
    if (params.action === 'delete') {
        params.action = 'update';
        params.args['data'] = { deletedAt: new Date() };
    }
    // Interceptar Find (ocultar borrados)
    if (params.action === 'findMany') {
        params.args.where = { ...params.args.where, deletedAt: null };
    }
    return next(params);
});
```

---

---

## Replicación (Escalado de Lectura)

Un solo nodo de DB aguanta ~2,000 writes/sec y ~10,000 reads/sec.
Si tienes 50,000 lecturas, tu DB va a morir.

### Master-Slave (Primary-Replica)
*   **Master:** Solo Acepta Writes (`INSERT`, `UPDATE`).
*   **Replicas:** Solo Aceptan Reads (`SELECT`). Copian datos del Master asíncronamente.

```javascript
/* Configuración en TypeORM */
replication: {
    master: { url: 'postgres://master-db:5432/db' },
    slaves: [
        { url: 'postgres://replica-1:5432/db' },
        { url: 'postgres://replica-2:5432/db' },
    ]
}
```
El ORM envía automáticamente los `SELECT` a las réplicas.

---

## Sharding (Escalado de Escritura)

Si tienes 1 TetraByte de datos, no cabe en un disco duro.
Partes la tabla `Users` en pedazos (Shards).

*   **Shard 1 (EU):** Usuarios A-M.
*   **Shard 2 (US):** Usuarios N-Z.

**Desventaja:** `JOIN` entre shards es casi imposible. Pierdes la integridad referencial.

---

## Caching Layer (Cache-Aside)

La DB es lenta (Disco). Redis es rápido (RAM).

### Patrón Cache-Aside
1.  Pides usuario X a Redis.
2.  ¿Existe? Devuélvelo (5ms).
3.  ¿No existe? Pídelo a DB (100ms) y guárdalo en Redis por 1h.

```javascript
async function getUser(id) {
    // 1. Check Cache
    const cached = await redis.get(`user:${id}`);
    if (cached) return JSON.parse(cached);

    // 2. Check DB
    const user = await db.users.find(id);
    
    // 3. Save Cache
    await redis.setex(`user:${id}`, 3600, JSON.stringify(user));
    
    return user;
}
```
**Regla de Oro:** Solo cachea lo que *casi no cambia* (Perfiles, Catálogos).

---

---

## Seguridad en DB (Blindando Datos)

### SQL Injection
El clásico `INPUT: ' OR 1=1 --`.
*   **Solución:** Parameterized Queries (Todos los ORMs lo hacen por defecto).
    ```javascript
    // Seguro
    db.query('SELECT * FROM users WHERE id = $1', [req.body.id]);
    ```

### Encryption at Rest
Si roban el disco duro del servidor, ¿pueden leer los datos?
*   **Transparent Data Encryption (TDE):** Postgres/MySQL lo soportan.
*   **Column Level Encryption:** Cifrar `credit_card` con AES-256 antes de guardar.
    ```javascript
    const cipher = crypto.createCipheriv('aes-256-cbc', key, iv);
    let encrypted = cipher.update(ccNumber, 'utf8', 'hex');
    encrypted += cipher.final('hex');
    // Guardar 'encrypted' en DB.
    ```

---

## Data Warehousing (ETL)

Tu DB operacional (OLTP) es para vender.
Tu DB analítica (OLAP) es para reportes mensuales.
No corras `SELECT SUM(sales) FROM orders` en producción, bloqueas la tabla.

### Flujo ETL (Extract, Transform, Load)
1.  **Extract:** Saca datos de Postgres a media noche.
2.  **Transform:** Limpia, desnormaliza y anonimiza.
3.  **Load:** Inserta en Snowflake / BigQuery / Redshift.

---

## Event Sourcing (La Verdad es la Historia)

En lugar de guardar "Saldo: $100", guardas:
1.  Depositó $50.
2.  Depositó $50.
3.  Retiró $20. (Total calculado: $80).

Si hay un error bancario, puedes reproducir la historia ("Replay") y corregirlo.
Es complejo, requiere **Kafka** o **EventStore**, pero es auditoría perfecta.

---

---

## Anti-Patrón: Base de Datos como Cola (Queue)

**Error Común:** Crear una tabla `Jobs` y hacer `SELECT * FROM Jobs WHERE status = 'PENDING'`.
*   **Problema:** Bloqueos (Locking). Si tienes 10 workers, se pelean por la misma fila.
*   **Solución:** Usa Redis / RabbitMQ / BullMQ. Las colas están hechas para esto.

---

## Datos de Series de Tiempo (IoT / Métricas)

Si guardas temperatura cada segundo (`INSERT INTO temp VALUES (25)`).
En un año tienes 31 millones de filas. Tu índice B-Tree colapsa.
*   **Solución:** TimescaleDB (Postgres Extension) o InfluxDB.
*   Particionan los datos por tiempo automáticamente.

---

## Datos Espaciales (PostGIS)

"Encuentra los restaurantes a 5km de mí".
En SQL normal, la fórmula Haversine es lenta (`O(N)`).
Con **PostGIS** (R-Tree Index), es instantáneo.

```sql
SELECT name 
FROM restaurants 
WHERE ST_DWithin(location, ST_MakePoint(-99.1, 19.4)::geography, 5000);
```

---

## Bases de Datos de Grafos (Neo4j)

"Amigos de mis amigos que les gustan los tacos".
En SQL es un `JOIN` triple (lento).
En Neo4j es recorrer el grafo (rápido).
*   **Uso:** Motores de recomendación, detección de fraude, redes sociales.

---

## Estrategias de Backup (Tu Seguro de Vida)

No es "si" falla, es "cuándo" falla.

### Logical Backup (`pg_dump`)
Genera un archivo SQL gigante.
*   **Pro:** Portable entre versiones.
*   **Contra:** Lento de restaurar (tiene que re-ejecutar todos los INSERT).

### Physical Backup (WAL Archiving)
Copia los bytes del disco duro (binario).
*   **Point-in-Time Recovery (PITR):** "¿Restaurar la DB a como estaba ayer a las 14:03:59?". SÍ.
*   Herramienta: `wal-g` o `pgbackrest`.

---

---

## Monitoreo de Bases de Datos (Slow Query Log)

Tu app está lenta. ¿Es Node o es Postgres?
Activa el `log_min_duration_statement = 200ms`.

### Analizando `pg_stat_statements`
Esta extensión te dice:
"La query `SELECT * FROM users` se ejecutó 50,000 veces y tardó 1.5s en promedio".
*   **Acción:** Agregar índice.

---

## Bases de Datos Serverless (Neon / Aurora)

Las DB tradicionales cobran por hora ($20/mes) aunque nadie las use.
Las Serverless cobran por query.
*   **Neon (Postgres):** Separa el almacenamiento del cómputo. Escala a cero si no hay tráfico.
*   **Ideal para:** Dev, Staging y Startups con tráfico irregular.

---

## Bases de Datos en el Edge (Turso / Cloudflare D1)

Si tu usuario está en Japón y tu DB en Virginia, hay 200ms de latencia.
DB en el Edge = Replicación automática en 300 ciudades.
*   **Turso (LibSQL):** Fork de SQLite que corre en todas partes.
*   **D1:** La base de datos SQL de Cloudflare.

---

## Patrones Multi-Tenancy (SaaS)

Tienes 1000 clientes (empresas). ¿Cómo separas sus datos?

### Columna Discriminadora (Cheap)
Todos en la misma tabla `users`. Columna `tenant_id`.
*   **Riesgo:** Un bug en el `WHERE` y Pepsi ve los datos de Coca-Cola.
*   **Solución:** Row Level Security (RLS) en Postgres.

### Schema por Tenant (Pro)
Misma DB, diferentes Schemas (`pepsi.users`, `coca.users`).
*   **Pro:** Aislamiento total. Backup individual.

---

## Teorema CAP (La Realidad Distribuida)

En un sistema distribuido, SOLO puedes tener 2 de 3:
1.  **C**onsistency (Todos ven el mismo dato al mismo tiempo).
2.  **A**vailability (El sistema siempre responde, aunque sea datos viejos).
3.  **P**artition Tolerance (El sistema aguanta si se corta el cable de red).

Como P es obligatorio en Internet, eliges **CP** (Bancos) o **AP** (Redes Sociales).
*   **Postgres:** CP (Si el master cae, hay downtime hasta promover réplica).
*   **Cassandra:** AP (Siempre responde, pero quizá no veas tu Post inmediatamente).

---

---

## Persistencia Políglota (Usar la Herramienta Correcta)

No uses un martillo para todo.
*   **Postgres:** Usuarios, Pagos (Relacional).
*   **Redis:** Sesiones, Caché (Rápido).
*   **Mongo:** Logs, Catálogos flexibles (Documentos).
*   **Neo4j:** Red de amigos (Grafos).

Tu backend orquesta todo esto.

---

## CQRS (Command Query Responsibility Segregation)

Separar los modelos de Lectura y Escritura.
*   **Write Model:** Normalizado (3NF). Optimizado para `INSERT` sin duplicidad.
*   **Read Model:** Desnormalizado. Una tabla `UserDashboard` que ya tiene todo pegado listo para leer.

Si usas Event Sourcing, CQRS es casi obligatorio.

---

## Normalización (Repaso Express)

*   **1NF:** Celdas atómicas (No arrays en una celda).
*   **2NF:** Todo depende de la Primary Key completa.
*   **3NF:** Y nada más que de la Primary Key (No dependencias transitivas).
*   **Desnormalizar:** A veces rompes la 3NF a propósito por performance (guardar `nombre_usuario` en la tabla `ventas` para no hacer JOIN).

---

## El Futuro: Bases de Datos Vectoriales (AI)

Para usar IA (Embeddings), no buscas texto exacto ("gato").
Buscas significado (Vectores `[0.1, 0.9, ...]`).
*   **pgvector:** Extensión de Postgres para búsqueda semántica.
*   **Pinecone / Chroma:** DBs nativas para IA.

```sql
SELECT * FROM items ORDER BY embedding <-> '[0.1, 0.3, ...]' LIMIT 5;
```
Esto encuentra "perro" cuando buscas "gato" porque semánticamente están cerca.

---

---

## Niveles de Aislamiento (Isolation Levels)

ACID dice "Aislado", pero ¿qué tanto?
Cuanto más aislado, más lento.

1.  **Read Uncommitted:** Lees datos sucios (Dirty Read) que aún no se guardan. **Peligroso.**
2.  **Read Committed:** (Default en Postgres). Solo lees lo confirmado.
3.  **Repeatable Read:** Si lees la fila X dos veces en la misma transacción, garantizas ver lo mismo (aunque alguien más la haya editado).
4.  **Serializable:** El bloqueo total. Es como si ejecutaras las transacciones una por una. Lento pero perfecto.

---

## Distributed Locking (Semáforos)

Si tienes 5 servidores Node.js intentando cobrar la misma suscripción a las 00:00.
¿Cómo evitas cobrar 5 veces?
Usa **Redis Redlock**.

```javascript
const lock = await redlock.acquire(["locks:cobro:usuario1"], 5000);
try {
    await cobrarSuscripcion();
} finally {
    await lock.release();
}
```
Solo UNO gana el lock. Los otros 4 fallan y esperan.

---

## Paginación: Offset vs Cursor

*   **Offset Pagination (Mala):** `LIMIT 10 OFFSET 1000000`.
    La DB tiene que leer y tirar 1 millón de filas antes de darte las 10 que quieres. Lento.
*   **Cursor Pagination (Buena):** `WHERE id > 1000000 LIMIT 10`.
    Usa el índice. Instantáneo.
    *   **Desventaja:** No puedes saltar a la página 500. Solo "Siguiente/Anterior".

---

## Stored Procedures (Lógica en DB)

¿Debes escribir tu lógica en JavaScript o en PL/pgSQL?

*   **JavaScript:** Fácil de testear, versionar y escalar (pones más servidores Node).
*   **PL/pgSQL:** Ultra rápido (datos y lógica viven juntos), pero difícil de mantener y migrar.

**Veredicto 2025:** Usa JS para lógica de negocio. Usa Stored Procedures solo para triggers de integridad referencial muy complejos.

---

---

## UUID vs Serial IDs (La Guerra de las Keys)

¿Tu ID debe ser `1` o `a0eebc99-9c0b...`?

### Serial (Auto Increment)
*   **Pro:** Ocupa 4 bytes. Rápido de indexar (B-Tree ama el orden).
*   **Contra:** Predecible. Si soy el user `100`, sé que existe el `99`. (`/users/99`).
*   **Problema:** Difícil en sistemas distribuídos (Master-Master replication colisiona).

### UUID v4 (Random)
*   **Pro:** Universalmente único. Puedes generar IDs en el cliente offline. Seguro (no adivinable).
*   **Contra:** Ocupa 16 bytes. Fragmenta los índices (lento `INSERT`).

**Veredicto:** Usa **UUID v7** (Tiempo + Random). Es ordenable cronológicamente y rápido como Serial.

---

## DataLoader (Matando el N+1 limpio)

El patrón estándar de GraphQL, pero útil en REST.
Acumula peticiones en 1 tick del Event Loop y las dispara juntas.

```javascript
const DataLoader = require('dataloader');

const userLoader = new DataLoader(async (keys) => {
    // keys = [1, 2, 5, 1, 2]
    const users = await db.users.findMany({ where: { id: { in: keys } } });
    // Ordenar users igual que keys...
    return keys.map(key => users.find(u => u.id === key));
});

// En tu Controller/Resolver
// Pides 5 veces, pero DataLoader hace 1 sola query a DB
await Promise.all([
    userLoader.load(1),
    userLoader.load(2),
    userLoader.load(5)
]);
```

---

<div align="center">

[⬅️ Anterior: 4.5 Creación de Clases](4.5.md) &nbsp;&nbsp;|&nbsp;&nbsp; [Siguiente: Unidad 5](../unidad5/README.md) ➡️

</div>
